{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'executorCores': 4, 'executorMemory': '9486M', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\"executorCores\": 4, \"executorMemory\": \"9486M\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>14</td><td>application_1564479621651_0015</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-3-240.eu-west-2.compute.internal:20888/proxy/application_1564479621651_0015/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-3-164.eu-west-2.compute.internal:8042/node/containerlogs/container_1564479621651_0015_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import html2text\n",
    "from smart_open import smart_open\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "import json\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import scrapy\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "import html2text\n",
    "from urllib.parse import urlparse, ParseResult\n",
    "from scrapy.linkextractors import IGNORED_EXTENSIONS\n",
    "from scrapy.selector import Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_file = \"s3://onai-ml-dev-eu-west-1/web_crawler/data/seed_urls/company-urls.csv\"\n",
    "\n",
    "def extract_text_from_html(html, upper_bound=10000):\n",
    "    if len(html) > upper_bound:\n",
    "        html =  html[:upper_bound]\n",
    "    parser = html2text.HTML2Text()\n",
    "    parser.wrap_links = False\n",
    "    parser.skip_internal_links = True\n",
    "    parser.inline_links = True\n",
    "    parser.ignore_anchors = True\n",
    "    parser.ignore_images = True\n",
    "    parser.ignore_emphasis = True\n",
    "    parser.ignore_links = True\n",
    "    return parser.handle(html)\n",
    "\n",
    "def convert_url(url):\n",
    "    p = urlparse(url, 'http')\n",
    "    netloc = p.netloc or p.path\n",
    "    path = p.path if p.netloc else ''\n",
    "    if not netloc.startswith('www.'):\n",
    "        netloc = 'www.' + netloc\n",
    "\n",
    "    p = ParseResult('http', netloc, path, *p[3:])\n",
    "    return p.geturl()\n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = \"my_spider\"\n",
    "\n",
    "    # crawl in BFS\n",
    "    custom_settings = {\n",
    "        'DEPTH_LIMIT': 2,\n",
    "        'DEPTH_PRIORITY': 1,\n",
    "        'SCHEDULER_DISK_QUEUE': 'scrapy.squeues.PickleFifoDiskQueue',\n",
    "        'SCHEDULER_MEMORY_QUEUE': 'scrapy.squeues.FifoMemoryQueue',\n",
    "        'SCHEDULER_PRIORITY_QUEUE': 'scrapy.pqueues.DownloaderAwarePriorityQueue',\n",
    "        'DNS_TIMEOUT': 20,\n",
    "        'DOWNLOAD_TIMEOUT': 30,\n",
    "        'LOG_LEVEL': 'ERROR',\n",
    "        'CONCURRENT_REQUESTS': 100,\n",
    "        'REACTOR_THREADPOOL_MAXSIZE': 20,        \n",
    "        'REDIRECT_ENABLED': False,\n",
    "        'RETRY_ENABLED': False,\n",
    "    }\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "#         runners.add(1)\n",
    "        start_urls = kwargs.get('start_urls')\n",
    "        parsed_urls = [urlparse(start_url) for start_url in start_urls]\n",
    "        url_domains = [parsed_url.netloc for parsed_url in parsed_urls]\n",
    "        self.allowed_domains = url_domains\n",
    "\n",
    "        self.output = kwargs.get('output')\n",
    "\n",
    "        self.allowed_extensions = ('.pdf', '.doc', '.xls', '.docx', '.xlsx')\n",
    "        self.denied_extensions = tuple(set(['.' + ext for ext in IGNORED_EXTENSIONS]) - set(self.allowed_extensions))\n",
    "\n",
    "        super(MySpider, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def save_file(self, response, upper_limit=2000000): # ~ 2 mbs tops\n",
    "        page_url = response.meta.get('page_url')\n",
    "        root_title = response.meta.get(\"root_title\")\n",
    "\n",
    "        path = response.url.split('/')[-1]\n",
    "        filename = path[path.rfind(\"/\") + 1:]\n",
    "#         print(\"File:\", filename)\n",
    "        if len(response.body) < upper_limit:\n",
    "            self.output.append((root_title, page_url, filename, \"file\", bytearray(response.body)))\n",
    "\n",
    "    def parse(self, response):\n",
    "        title_xpath = response.selector.xpath('//title/text()').extract()\n",
    "        \n",
    "        page_title = title_xpath[0] if title_xpath else \"\"\n",
    "        \n",
    "        root_title = response.meta.get(\"root_title\")\n",
    "        if root_title is None:\n",
    "            root_title = page_title\n",
    "        \n",
    "        page_content = extract_text_from_html(response.text)\n",
    "        self.log('Page: %s (%s)' % (response.url, page_title))\n",
    "\n",
    "        extracted_links = LinkExtractor().extract_links(response)\n",
    "        for link in extracted_links:\n",
    "            url = link.url\n",
    "            parsed_url = urlparse(url)\n",
    "            url_domain = parsed_url.netloc\n",
    "            \n",
    "            follow_link = False\n",
    "            for marker in ['who we are', 'overview', 'about', 'mission']:\n",
    "                if marker in link.url.lower():\n",
    "                    follow_link = True\n",
    "\n",
    "            for marker in ['who we are', 'overview', 'about', 'mission']:\n",
    "                if marker in link.text.lower():\n",
    "                    follow_link = True\n",
    "                    \n",
    "            if not follow_link:\n",
    "                continue\n",
    "\n",
    "            if url_domain in self.allowed_domains:\n",
    "                if link.url.endswith(self.allowed_extensions):\n",
    "                    yield scrapy.Request(url,\n",
    "                                         callback=self.save_file,\n",
    "                                         meta={'page_url': response.url, \n",
    "                                               'root_title':root_title\n",
    "                                              }\n",
    "                                        )\n",
    "                elif link.url.endswith(self.denied_extensions):\n",
    "                    continue\n",
    "                else:\n",
    "                    yield scrapy.Request(url, callback=self.parse, meta={'root_title': root_title})\n",
    "        \n",
    "        self.output.append((root_title, response.url, page_title, \"html\", page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandas_df = pd.read_csv(input_file, header=0, sep='\\t').astype(str)\n",
    "df = spark.createDataFrame(pandas_df).repartition(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_scraper(urls):\n",
    "    from multiprocessing import Process, Queue\n",
    "    \n",
    "    import twisted.internet.reactor as reactor\n",
    "    from twisted.internet import default, defer, task\n",
    "    from scrapy.crawler import CrawlerRunner\n",
    "\n",
    "    def f(q, output_q):\n",
    "        try:\n",
    "            data = []\n",
    "            runner = CrawlerRunner()\n",
    "            deferred = runner.crawl(MySpider, start_urls=[convert_url(url) for url in urls], output=data)\n",
    "            deferred.addBoth(lambda _: reactor.stop())\n",
    "            reactor.run()\n",
    "            q.put(None)\n",
    "            output_q.put(data)\n",
    "            raise ValueError(data)\n",
    "        except Exception as e:\n",
    "            q.put(e)\n",
    "\n",
    "    q = Queue()\n",
    "    output_q = Queue()\n",
    "    p = Process(target=f, args=(q, output_q))\n",
    "    p.start()\n",
    "    error = q.get()\n",
    "    output = output_q.get()\n",
    "    p.join()\n",
    "\n",
    "    if error is not None:\n",
    "        raise error\n",
    "\n",
    "    return output\n",
    "\n",
    "def run_spider(urls):\n",
    "    from twisted.internet import reactor\n",
    "    from scrapy.crawler import CrawlerRunner\n",
    "    \n",
    "    from crochet import setup, wait_for, TimeoutError\n",
    "    setup()\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    @wait_for(timeout=200.0)\n",
    "    def run_it_already():\n",
    "        crawler = CrawlerRunner()\n",
    "        return crawler.crawl(MySpider, start_urls=[convert_url(url) for url in urls], output=data)\n",
    "    \n",
    "    try:\n",
    "        run_it_already()\n",
    "    except TimeoutError:\n",
    "        # In case of timeout, just return what we managed to scrape\n",
    "        print(\"Timed out for given URLs\", list(urls))\n",
    "        print(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_urls = pandas_df[\"url\"].iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:twisted:Log opened.\n",
      "INFO:scrapy.crawler:Overridden settings: {'CONCURRENT_REQUESTS': 100, 'DEPTH_LIMIT': 2, 'DEPTH_PRIORITY': 1, 'DNS_TIMEOUT': 20, 'DOWNLOAD_TIMEOUT': 30, 'LOG_LEVEL': 'ERROR', 'REACTOR_THREADPOOL_MAXSIZE': 20, 'REDIRECT_ENABLED': False, 'RETRY_ENABLED': False, 'SCHEDULER_DISK_QUEUE': 'scrapy.squeues.PickleFifoDiskQueue', 'SCHEDULER_MEMORY_QUEUE': 'scrapy.squeues.FifoMemoryQueue', 'SCHEDULER_PRIORITY_QUEUE': 'scrapy.pqueues.DownloaderAwarePriorityQueue'}\n",
      "INFO:scrapy.extensions.telnet:Telnet Password: 22a60bc0b7dc693d\n",
      "INFO:scrapy.middleware:Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "INFO:scrapy.middleware:Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "INFO:scrapy.middleware:Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "INFO:scrapy.middleware:Enabled item pipelines:\n",
      "[]\n",
      "INFO:scrapy.core.engine:Spider opened\n",
      "INFO:scrapy.extensions.logstats:Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "INFO:twisted:TelnetConsole starting on 6023\n",
      "INFO:scrapy.extensions.telnet:Telnet console listening on 127.0.0.1:6023\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.aspmedialtd.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.momentousuk.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.woodman.ch> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.larrybodine.com> (referer: None)\n",
      "ERROR:scrapy.core.scraper:Error downloading <GET http://www.youronlinetvchannel.com>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 1416, in _inlineCallbacks\n",
      "    result = result.throwExceptionIntoGenerator(g)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/python/failure.py\", line 512, in throwExceptionIntoGenerator\n",
      "    return g.throw(self.type, self.value, self.tb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py\", line 44, in process_request\n",
      "    defer.returnValue((yield download_func(request=request, spider=spider)))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 654, in _runCallbacks\n",
      "    current.result = callback(current.result, *args, **kw)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/endpoints.py\", line 975, in startConnectionAttempts\n",
      "    \"no results for hostname lookup: {}\".format(self._hostStr)\n",
      "twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.youronlinetvchannel.com.\n",
      "DEBUG:my_spider:Page: http://www.aspmedialtd.com (aspmedialtd.com)\n",
      "DEBUG:my_spider:Page: http://www.momentousuk.com (momentous)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.presentationfactor.com> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.woodman.ch>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.casebio.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.paymentsecuritypros.com> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.larrybodine.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (302) <GET http://www.kumatech.ca> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.cintas.co.uk> (referer: None)\n",
      "DEBUG:my_spider:Page: http://www.presentationfactor.com (Welcome to the Presentation Factor)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.wcngroup.com> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.paymentsecuritypros.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.arrowmediagroup.wordpress.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.ravica.com> (referer: None)\n",
      "DEBUG:my_spider:Page: http://www.casebio.com ()\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.refrigeratedtransporter.com> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <302 http://www.kumatech.ca>: HTTP status code is not handled or not allowed\n",
      "DEBUG:my_spider:Page: http://www.cintas.co.uk ()\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.genroe.com> (referer: None)\n",
      "DEBUG:my_spider:Page: http://www.wcngroup.com ()\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.arrowmediagroup.wordpress.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.alava-ing.es> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.ravica.com>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.refrigeratedtransporter.com>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.genroe.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (302) <GET http://www.rochestermn.gov> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.alava-ing.es>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (302) <GET http://www.ogra.org> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <302 http://www.rochestermn.gov>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <302 http://www.ogra.org>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.cloudmj.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.adam.co.uk> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (302) <GET http://www.nils.us> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.ssda.org> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.davarcci.com> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.cloudmj.com>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.adam.co.uk>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.flo-2d.com> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <302 http://www.nils.us>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (302) <GET http://www.thei3p.org> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.vizualms.co.uk> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.phschiropractic.com> (referer: None)\n",
      "DEBUG:scrapy.downloadermiddlewares.redirect:Redirecting (meta refresh) to <GET http://searchguide.level3.com/search/?q=http://www.soliloquy.ltd.uk%2F&bc=> from <GET http://www.soliloquy.ltd.uk>\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.justbusinessresults.com> (referer: None)\n",
      "DEBUG:my_spider:Page: http://www.ssda.org (Small School Districts’ Association)\n",
      "DEBUG:my_spider:Page: http://www.davarcci.com (Davarcci)\n",
      "ERROR:scrapy.core.scraper:Error downloading <GET http://www.omniscientllc.com>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 1416, in _inlineCallbacks\n",
      "    result = result.throwExceptionIntoGenerator(g)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/python/failure.py\", line 512, in throwExceptionIntoGenerator\n",
      "    return g.throw(self.type, self.value, self.tb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py\", line 44, in process_request\n",
      "    defer.returnValue((yield download_func(request=request, spider=spider)))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 654, in _runCallbacks\n",
      "    current.result = callback(current.result, *args, **kw)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/endpoints.py\", line 975, in startConnectionAttempts\n",
      "    \"no results for hostname lookup: {}\".format(self._hostStr)\n",
      "twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.omniscientllc.com.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.amaiowa.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.sol-distribution.co.uk> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (302) <GET http://www.expresspersonel.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.h2glenfern.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.patientsafetyauthority.org> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.flo-2d.com>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <302 http://www.thei3p.org>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.vizualms.co.uk>: HTTP status code is not handled or not allowed\n",
      "ERROR:scrapy.core.scraper:Error downloading <GET http://www.appaturemobile.com>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 1416, in _inlineCallbacks\n",
      "    result = result.throwExceptionIntoGenerator(g)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/python/failure.py\", line 512, in throwExceptionIntoGenerator\n",
      "    return g.throw(self.type, self.value, self.tb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py\", line 44, in process_request\n",
      "    defer.returnValue((yield download_func(request=request, spider=spider)))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 654, in _runCallbacks\n",
      "    current.result = callback(current.result, *args, **kw)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/endpoints.py\", line 975, in startConnectionAttempts\n",
      "    \"no results for hostname lookup: {}\".format(self._hostStr)\n",
      "twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.appaturemobile.com.\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.phschiropractic.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.pinefinancialgroup.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (302) <GET http://www.infservice.com.br> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.amaiowa.com>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <302 http://www.expresspersonel.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:my_spider:Page: http://www.justbusinessresults.com ()\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.patientsafetyauthority.org>: HTTP status code is not handled or not allowed\n",
      "DEBUG:my_spider:Page: http://www.sol-distribution.co.uk (Sol Distribution - UK Based Networking Hardware Distributor | Sol Distribution)\n",
      "DEBUG:my_spider:Page: http://www.h2glenfern.com (Home - h2glenfern)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.say-ah.org> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.pinefinancialgroup.com>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <302 http://www.infservice.com.br>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.ssda.org/about--82> (referer: http://www.ssda.org)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.sassetti.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.recyclefloridatoday.org> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.shipham-valves.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.ruderfinn.co.uk> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.say-ah.org>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.xmlstar.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.lippis.com> (referer: None)\n",
      "DEBUG:my_spider:Page: http://www.ssda.org/about--82 (Small School Districts’ Association)\n",
      "DEBUG:scrapy.dupefilters:Filtered duplicate request: <GET http://www.ssda.org/about--82> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.businesscareercollege.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.courthouseclinics.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.coultertm.com> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.sassetti.com>: HTTP status code is not handled or not allowed\n",
      "ERROR:scrapy.core.scraper:Error downloading <GET http://www.sianjones.biz>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 1416, in _inlineCallbacks\n",
      "    result = result.throwExceptionIntoGenerator(g)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/python/failure.py\", line 512, in throwExceptionIntoGenerator\n",
      "    return g.throw(self.type, self.value, self.tb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py\", line 44, in process_request\n",
      "    defer.returnValue((yield download_func(request=request, spider=spider)))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 654, in _runCallbacks\n",
      "    current.result = callback(current.result, *args, **kw)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/endpoints.py\", line 975, in startConnectionAttempts\n",
      "    \"no results for hostname lookup: {}\".format(self._hostStr)\n",
      "twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.sianjones.biz.\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.recyclefloridatoday.org>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.shipham-valves.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.northbabylonschools.net> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.subaru.ie> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.solarpst.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.radtech.org> (referer: None)\n",
      "DEBUG:my_spider:Page: http://www.ruderfinn.co.uk (Home Page - RuderFinn)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.xmlstar.com>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.lippis.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.wellnessworkdays.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.tradermade.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.bondcasebriefs.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.qualitycolor.com.co> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.theosophical.org> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.businesscareercollege.com>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.courthouseclinics.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.aafcleveland.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.managementconsultants.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.elcbroward.org> (referer: None)\n",
      "DEBUG:my_spider:Page: http://www.coultertm.com (Braun Electric Shaver Reviews | CoulterTM)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.radtech.org>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.blomquisthale.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.capitalcitymedia.co.uk> (referer: None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.takeitglobal.co.uk> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.bestinc.org> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.rowekamp.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.davidmeermanscott.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.waltonpost.com> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.wellnessworkdays.com>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.tradermade.com>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.bondcasebriefs.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:my_spider:Page: http://www.northbabylonschools.net (\n",
      "\tNorth Babylon School District\n",
      ")\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.qualitycolor.com.co>: HTTP status code is not handled or not allowed\n",
      "DEBUG:my_spider:Page: http://www.subaru.ie (Subaru - Home)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.theosophical.org>: HTTP status code is not handled or not allowed\n",
      "DEBUG:my_spider:Page: http://www.solarpst.com (SolarPST - Paneles Solares Termodinámicos | ACS | Agua caliente | Calefacción | Termodiámica | Ahorro Energético | Bomba de calor)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.managementconsultants.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.navitron.org.uk> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.growtivity.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.presentationxpert.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.ruderfinn.co.uk/index.php/about/> (referer: http://www.ruderfinn.co.uk)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.glc.org> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.blomquisthale.com>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.capitalcitymedia.co.uk>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.davidmeermanscott.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:my_spider:Page: http://www.aafcleveland.com (AAF Cleveland)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.justinflitter.com> (referer: None)\n",
      "DEBUG:my_spider:Page: http://www.elcbroward.org (Early Learning Coalition of Broward County, Inc - Home)\n",
      "DEBUG:my_spider:Page: http://www.takeitglobal.co.uk (Hosted By One.com | Webhosting made simple)\n",
      "DEBUG:my_spider:Page: http://www.bestinc.org (Best Robotics Inc. - Boosting Engineering Science and Technology)\n",
      "DEBUG:my_spider:Page: http://www.rowekamp.com (Rowekamp Associates Home)\n",
      "DEBUG:my_spider:Page: http://www.waltonpost.com (Walton & Post | Providing Excellence in Distribution)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.navitron.org.uk>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.growtivity.com>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.glc.org>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (403) <GET http://www.tuitionexchange.org> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.newenglandkiwanis.org> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.northbabylonschools.net/our_district/mission_and_vision_statement> (referer: http://www.northbabylonschools.net)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.justinflitter.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:my_spider:Page: http://www.presentationxpert.com (Presentation Xpert -  Buyer's Guides, Directories and or Exhibitor Lists)\n",
      "DEBUG:my_spider:Page: http://www.ruderfinn.co.uk/index.php/about/ (About - RuderFinn)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.takeitglobal.co.uk#about> (referer: http://www.takeitglobal.co.uk)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.southbaybmw.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.winningwork.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.fgs.org> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.davarcci.com/aboutus_home.htm> (referer: http://www.davarcci.com)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.ssda.org/mission-statement--31> (referer: http://www.ssda.org)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <403 http://www.tuitionexchange.org>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.bestinc.org> (referer: http://www.bestinc.org)\n",
      "DEBUG:my_spider:Page: http://www.newenglandkiwanis.org (New England and Bermuda District of Kiwanis)\n",
      "DEBUG:my_spider:Page: http://www.northbabylonschools.net/our_district/mission_and_vision_statement (\n",
      "\tNorth Babylon School District District | Mission and Vision Statement\n",
      ")\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.waltonpost.com/about> (referer: http://www.waltonpost.com)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.gimbalcanada.com> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.fgs.org>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.civicgovernance.ca> (referer: None)\n",
      "DEBUG:my_spider:Page: http://www.takeitglobal.co.uk (Hosted By One.com | Webhosting made simple)\n",
      "DEBUG:my_spider:Page: http://www.southbaybmw.com ()\n",
      "DEBUG:my_spider:Page: http://www.winningwork.com (winningwork.com -&nbspThis website is for sale! -&nbsp Resources and Information.)\n",
      "DEBUG:my_spider:Page: http://www.davarcci.com/aboutus_home.htm (Davarcci)\n",
      "DEBUG:my_spider:Page: http://www.ssda.org/mission-statement--31 (Small School Districts’ Association)\n",
      "DEBUG:my_spider:Page: http://www.bestinc.org (Best Robotics Inc. - Boosting Engineering Science and Technology)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://searchguide.level3.com/search/?q=http://www.soliloquy.ltd.uk%2F&bc=> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.aafcleveland.com/about-us/portfolio-back-issues/> (referer: http://www.aafcleveland.com)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.musigmagroup.com> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.waltonpost.com/about>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.gimbalcanada.com>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.civicgovernance.ca>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.examzone.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.thetacapital.com> (referer: None)\n",
      "DEBUG:my_spider:Page: http://searchguide.level3.com/search/?q=http://www.soliloquy.ltd.uk%2F&bc= (Search)\n",
      "DEBUG:scrapy.core.engine:Crawled (302) <GET http://www.elcbroward.org/p/3/about-the-coalition> (referer: http://www.elcbroward.org)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.bestinc.org/b_about_best.php> (referer: http://www.bestinc.org)\n",
      "DEBUG:my_spider:Page: http://www.aafcleveland.com/about-us/portfolio-back-issues/ (Portfolio Back Issues)\n",
      "DEBUG:my_spider:Page: http://www.musigmagroup.com ()\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.presentationxpert.com/about-us> (referer: http://www.presentationxpert.com)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.northbabylonschools.net/faculty_resources/new_teacher_overview> (referer: http://www.northbabylonschools.net)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:my_spider:Page: http://www.examzone.com (Examzone | Pass Your Exam!)\n",
      "DEBUG:my_spider:Page: http://www.thetacapital.com ( Theta Capital Management)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.trueblueclean.com> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <302 http://www.elcbroward.org/p/3/about-the-coalition>: HTTP status code is not handled or not allowed\n",
      "DEBUG:my_spider:Page: http://www.bestinc.org/b_about_best.php (Best Robotics Inc. - Boosting Engineering Science and Technology)\n",
      "DEBUG:my_spider:Page: http://www.presentationxpert.com/about-us (About Us | Presentation Xpert)\n",
      "DEBUG:my_spider:Page: http://www.northbabylonschools.net/faculty_resources/new_teacher_overview (\n",
      "\tNorth Babylon School District Faculty Resources | New Teacher Overview\n",
      ")\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.vaircompanies.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.aafcleveland.com/membership/overview/> (referer: http://www.aafcleveland.com)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.aafcleveland.com/about-us/committees/> (referer: http://www.aafcleveland.com)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.aafcleveland.com/about-us/overview/> (referer: http://www.aafcleveland.com)\n",
      "DEBUG:my_spider:Page: http://www.trueblueclean.com (True Blue Technologies, Inc.)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.aafcleveland.com/about-us/leadership/> (referer: http://www.aafcleveland.com)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.thetacapital.com/?page_id=7> (referer: http://www.thetacapital.com)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.invisiblefist.com> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.vaircompanies.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:my_spider:Page: http://www.aafcleveland.com/membership/overview/ (Overview)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.heritageohio.org> (referer: None)\n",
      "DEBUG:my_spider:Page: http://www.aafcleveland.com/about-us/committees/ (Get Involved)\n",
      "DEBUG:my_spider:Page: http://www.aafcleveland.com/about-us/overview/ (Overview)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.commsupplygroup.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.examzone.com/AboutUs> (referer: http://www.examzone.com)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.invisiblefist.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:my_spider:Page: http://www.aafcleveland.com/about-us/leadership/ (Leadership)\n",
      "DEBUG:my_spider:Page: http://www.thetacapital.com/?page_id=7 (  About us : Theta Capital Management)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.heritageohio.org>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.examzone.com/Aboutus> (referer: http://www.examzone.com)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.commsupplygroup.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.sustainabilityedge.com> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.elcbroward.org/p/94/early-learning-coalition-of-broward-strategic-plan-overview> (referer: http://www.elcbroward.org)\n",
      "DEBUG:my_spider:Page: http://www.examzone.com/AboutUs (Examzone | Pass Your Exam!)\n",
      "DEBUG:my_spider:Page: http://www.examzone.com/Aboutus (Examzone | Pass Your Exam!)\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.aafcleveland.com/about-us/portfolio-back-issues/tel:2169014000> (referer: http://www.aafcleveland.com/about-us/portfolio-back-issues/)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.sustainabilityedge.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.aafcleveland.com/about-us/aaf-cleveland-advertising-hall-of-fame/> (referer: http://www.aafcleveland.com)\n",
      "DEBUG:my_spider:Page: http://www.elcbroward.org/p/94/early-learning-coalition-of-broward-strategic-plan-overview (Early Learning Coalition of Broward County, Inc - Early Learning Coalition of Broward ‐ Strategic Plan Overview)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.ctls.net> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.aafcleveland.com/about-us/portfolio-back-issues/tel:216901400> (referer: http://www.aafcleveland.com/about-us/portfolio-back-issues/)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.trueblueclean.com/about.html> (referer: http://www.trueblueclean.com)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.jbbmobile.com> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.aafcleveland.com/about-us/portfolio-back-issues/tel:2169014000>: HTTP status code is not handled or not allowed\n",
      "DEBUG:my_spider:Page: http://www.aafcleveland.com/about-us/aaf-cleveland-advertising-hall-of-fame/ (AAF-Cleveland Advertising Hall of Fame)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.ctls.net>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.aafcleveland.com/about-us/portfolio-back-issues/tel:216901400>: HTTP status code is not handled or not allowed\n",
      "DEBUG:my_spider:Page: http://www.trueblueclean.com/about.html (About)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.jbbmobile.com>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.aafcleveland.com/membership/overview/tel:2169014000> (referer: http://www.aafcleveland.com/membership/overview/)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.aafcleveland.com/membership/overview/tel:2169014000>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.aafcleveland.com/membership/overview/tel:216901400> (referer: http://www.aafcleveland.com/membership/overview/)\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.aafcleveland.com/about-us/committees/tel:216901400> (referer: http://www.aafcleveland.com/about-us/committees/)\n",
      "DEBUG:scrapy.core.engine:Crawled (301) <GET http://www.cahealthadvocates.org> (referer: None)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.aafcleveland.com/membership/overview/tel:216901400>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.aafcleveland.com/about-us/committees/tel:216901400>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.aafcleveland.com/about-us/overview/tel:2169014000> (referer: http://www.aafcleveland.com/about-us/overview/)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <301 http://www.cahealthadvocates.org>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.aafcleveland.com/about-us/overview/tel:2169014000>: HTTP status code is not handled or not allowed\n",
      "ERROR:scrapy.core.scraper:Error downloading <GET http://www.ukocn.com>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py\", line 44, in process_request\n",
      "    defer.returnValue((yield download_func(request=request, spider=spider)))\n",
      "twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.aafcleveland.com/about-us/overview/tel:216901400> (referer: http://www.aafcleveland.com/about-us/overview/)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.aafcleveland.com/about-us/overview/tel:216901400>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.aafcleveland.com/about-us/leadership/tel:2169014000> (referer: http://www.aafcleveland.com/about-us/leadership/)\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.aafcleveland.com/about-us/committees/tel:2169014000> (referer: http://www.aafcleveland.com/about-us/committees/)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.aafcleveland.com/about-us/leadership/tel:2169014000>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.aafcleveland.com/about-us/committees/tel:2169014000>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.aafcleveland.com/about-us/leadership/tel:216901400> (referer: http://www.aafcleveland.com/about-us/leadership/)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.aafcleveland.com/about-us/leadership/tel:216901400>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.aafcleveland.com/about-us/aaf-cleveland-advertising-hall-of-fame/tel:2169014000> (referer: http://www.aafcleveland.com/about-us/aaf-cleveland-advertising-hall-of-fame/)\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.aafcleveland.com/about-us/aaf-cleveland-advertising-hall-of-fame/tel:216901400> (referer: http://www.aafcleveland.com/about-us/aaf-cleveland-advertising-hall-of-fame/)\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.aafcleveland.com/about-us/aaf-cleveland-advertising-hall-of-fame/tel:2169014000>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.aafcleveland.com/about-us/aaf-cleveland-advertising-hall-of-fame/tel:216901400>: HTTP status code is not handled or not allowed\n",
      "ERROR:scrapy.core.scraper:Error downloading <GET http://www.rcbc.bc.ca>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 1416, in _inlineCallbacks\n",
      "    result = result.throwExceptionIntoGenerator(g)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/python/failure.py\", line 512, in throwExceptionIntoGenerator\n",
      "    return g.throw(self.type, self.value, self.tb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py\", line 44, in process_request\n",
      "    defer.returnValue((yield download_func(request=request, spider=spider)))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 654, in _runCallbacks\n",
      "    current.result = callback(current.result, *args, **kw)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/endpoints.py\", line 975, in startConnectionAttempts\n",
      "    \"no results for hostname lookup: {}\".format(self._hostStr)\n",
      "twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.rcbc.bc.ca.\n",
      "ERROR:scrapy.core.scraper:Error downloading <GET http://www.bob-weber.com>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 1416, in _inlineCallbacks\n",
      "    result = result.throwExceptionIntoGenerator(g)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/python/failure.py\", line 512, in throwExceptionIntoGenerator\n",
      "    return g.throw(self.type, self.value, self.tb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py\", line 44, in process_request\n",
      "    defer.returnValue((yield download_func(request=request, spider=spider)))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 654, in _runCallbacks\n",
      "    current.result = callback(current.result, *args, **kw)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/endpoints.py\", line 975, in startConnectionAttempts\n",
      "    \"no results for hostname lookup: {}\".format(self._hostStr)\n",
      "twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.bob-weber.com.\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.jessicaproud.com> (referer: None)\n",
      "DEBUG:my_spider:Page: http://www.jessicaproud.com ()\n",
      "ERROR:scrapy.core.scraper:Error downloading <GET http://www.itstructures.com>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 1416, in _inlineCallbacks\n",
      "    result = result.throwExceptionIntoGenerator(g)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/python/failure.py\", line 512, in throwExceptionIntoGenerator\n",
      "    return g.throw(self.type, self.value, self.tb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py\", line 44, in process_request\n",
      "    defer.returnValue((yield download_func(request=request, spider=spider)))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 654, in _runCallbacks\n",
      "    current.result = callback(current.result, *args, **kw)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/handlers/http11.py\", line 352, in _cb_timeout\n",
      "    raise TimeoutError(\"Getting %s took longer than %s seconds.\" % (url, timeout))\n",
      "twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.itstructures.com took longer than 30.0 seconds..\n",
      "ERROR:scrapy.core.scraper:Error downloading <GET http://www.freestyleinteractive.com>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 1416, in _inlineCallbacks\n",
      "    result = result.throwExceptionIntoGenerator(g)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/python/failure.py\", line 512, in throwExceptionIntoGenerator\n",
      "    return g.throw(self.type, self.value, self.tb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py\", line 44, in process_request\n",
      "    defer.returnValue((yield download_func(request=request, spider=spider)))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 654, in _runCallbacks\n",
      "    current.result = callback(current.result, *args, **kw)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/handlers/http11.py\", line 352, in _cb_timeout\n",
      "    raise TimeoutError(\"Getting %s took longer than %s seconds.\" % (url, timeout))\n",
      "twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.freestyleinteractive.com took longer than 30.0 seconds..\n",
      "ERROR:scrapy.core.scraper:Error downloading <GET http://www.trcoworld.com>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 1416, in _inlineCallbacks\n",
      "    result = result.throwExceptionIntoGenerator(g)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/python/failure.py\", line 512, in throwExceptionIntoGenerator\n",
      "    return g.throw(self.type, self.value, self.tb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py\", line 44, in process_request\n",
      "    defer.returnValue((yield download_func(request=request, spider=spider)))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 654, in _runCallbacks\n",
      "    current.result = callback(current.result, *args, **kw)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/handlers/http11.py\", line 352, in _cb_timeout\n",
      "    raise TimeoutError(\"Getting %s took longer than %s seconds.\" % (url, timeout))\n",
      "twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.trcoworld.com took longer than 30.0 seconds..\n",
      "ERROR:scrapy.core.scraper:Error downloading <GET http://www.hawickgroup.com>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 1416, in _inlineCallbacks\n",
      "    result = result.throwExceptionIntoGenerator(g)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/python/failure.py\", line 512, in throwExceptionIntoGenerator\n",
      "    return g.throw(self.type, self.value, self.tb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/middleware.py\", line 44, in process_request\n",
      "    defer.returnValue((yield download_func(request=request, spider=spider)))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/twisted/internet/defer.py\", line 654, in _runCallbacks\n",
      "    current.result = callback(current.result, *args, **kw)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/scrapy/core/downloader/handlers/http11.py\", line 352, in _cb_timeout\n",
      "    raise TimeoutError(\"Getting %s took longer than %s seconds.\" % (url, timeout))\n",
      "twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.hawickgroup.com took longer than 30.0 seconds..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:scrapy.core.engine:Closing spider (finished)\n",
      "INFO:scrapy.statscollectors:Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 11,\n",
      " 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 6,\n",
      " 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 4,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,\n",
      " 'downloader/request_bytes': 34445,\n",
      " 'downloader/request_count': 136,\n",
      " 'downloader/request_method_count/GET': 136,\n",
      " 'downloader/response_bytes': 707113,\n",
      " 'downloader/response_count': 125,\n",
      " 'downloader/response_status_count/200': 54,\n",
      " 'downloader/response_status_count/301': 50,\n",
      " 'downloader/response_status_count/302': 8,\n",
      " 'downloader/response_status_count/403': 1,\n",
      " 'downloader/response_status_count/404': 12,\n",
      " 'dupefilter/filtered': 67,\n",
      " 'elapsed_time_seconds': 30.614818,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2019, 7, 30, 14, 53, 22, 290167),\n",
      " 'httperror/response_ignored_count': 71,\n",
      " 'httperror/response_ignored_status_count/301': 50,\n",
      " 'httperror/response_ignored_status_count/302': 8,\n",
      " 'httperror/response_ignored_status_count/403': 1,\n",
      " 'httperror/response_ignored_status_count/404': 12,\n",
      " 'log_count/ERROR': 11,\n",
      " 'memusage/max': 145604608,\n",
      " 'memusage/startup': 145604608,\n",
      " 'request_depth_max': 2,\n",
      " 'response_received_count': 124,\n",
      " 'scheduler/dequeued': 136,\n",
      " 'scheduler/dequeued/memory': 136,\n",
      " 'scheduler/enqueued': 136,\n",
      " 'scheduler/enqueued/memory': 136,\n",
      " 'start_time': datetime.datetime(2019, 7, 30, 14, 52, 51, 675349)}\n",
      "INFO:scrapy.core.engine:Spider closed (finished)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.64 s, sys: 560 ms, total: 4.2 s\n",
      "Wall time: 30.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:twisted:(TCP Port 6023 Closed)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data1 = run_spider(tst_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tSession 3 unexpectedly reached final status 'dead'. See logs:\n",
      "stdout: \n",
      "\n",
      "stderr: \n",
      "19/07/31 11:01:16 INFO RSCDriver: Connecting to: ip-10-0-3-246.eu-west-2.compute.internal:10000\n",
      "19/07/31 11:01:16 INFO RSCDriver: Starting RPC server...\n",
      "19/07/31 11:01:16 INFO RpcServer: Connected to the port 10001\n",
      "19/07/31 11:01:16 WARN RSCConf: Your hostname, ip-10-0-3-246.eu-west-2.compute.internal, resolves to a loopback address, but we couldn't find any external IP address!\n",
      "19/07/31 11:01:16 WARN RSCConf: Set livy.rsc.rpc.server.address if you need to bind to another address.\n",
      "19/07/31 11:01:16 INFO RSCDriver: Received job request 05ef6139-f493-4f19-848d-9cc8df970b9e\n",
      "19/07/31 11:01:16 INFO RSCDriver: SparkContext not yet up, queueing job request.\n",
      "19/07/31 11:01:22 INFO SparkEntries: Starting Spark context...\n",
      "19/07/31 11:01:22 INFO SparkContext: Running Spark version 2.4.2\n",
      "19/07/31 11:01:22 INFO SparkContext: Submitted application: livy-session-3\n",
      "19/07/31 11:01:22 INFO SecurityManager: Changing view acls to: livy\n",
      "19/07/31 11:01:22 INFO SecurityManager: Changing modify acls to: livy\n",
      "19/07/31 11:01:22 INFO SecurityManager: Changing view acls groups to: \n",
      "19/07/31 11:01:22 INFO SecurityManager: Changing modify acls groups to: \n",
      "19/07/31 11:01:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(livy); groups with view permissions: Set(); users  with modify permissions: Set(livy); groups with modify permissions: Set()\n",
      "19/07/31 11:01:22 INFO Utils: Successfully started service 'sparkDriver' on port 38251.\n",
      "19/07/31 11:01:22 INFO SparkEnv: Registering MapOutputTracker\n",
      "19/07/31 11:01:22 INFO SparkEnv: Registering BlockManagerMaster\n",
      "19/07/31 11:01:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "19/07/31 11:01:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "19/07/31 11:01:22 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-91c567aa-eefb-44d3-a150-5f8664fe7a05\n",
      "19/07/31 11:01:22 INFO MemoryStore: MemoryStore started with capacity 410.0 MB\n",
      "19/07/31 11:01:22 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "19/07/31 11:01:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "19/07/31 11:01:23 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-10-0-3-246.eu-west-2.compute.internal:4040\n",
      "19/07/31 11:01:23 INFO SparkContext: Added JAR file:/usr/lib/livy/rsc-jars/netty-all-4.0.37.Final.jar at spark://ip-10-0-3-246.eu-west-2.compute.internal:38251/jars/netty-all-4.0.37.Final.jar with timestamp 1564570883196\n",
      "19/07/31 11:01:23 INFO SparkContext: Added JAR file:/usr/lib/livy/rsc-jars/livy-api-0.6.0-incubating.jar at spark://ip-10-0-3-246.eu-west-2.compute.internal:38251/jars/livy-api-0.6.0-incubating.jar with timestamp 1564570883197\n",
      "19/07/31 11:01:23 INFO SparkContext: Added JAR file:/usr/lib/livy/rsc-jars/livy-rsc-0.6.0-incubating.jar at spark://ip-10-0-3-246.eu-west-2.compute.internal:38251/jars/livy-rsc-0.6.0-incubating.jar with timestamp 1564570883197\n",
      "19/07/31 11:01:23 INFO SparkContext: Added JAR file:/usr/lib/livy/repl_2.11-jars/commons-codec-1.9.jar at spark://ip-10-0-3-246.eu-west-2.compute.internal:38251/jars/commons-codec-1.9.jar with timestamp 1564570883198\n",
      "19/07/31 11:01:23 INFO SparkContext: Added JAR file:/usr/lib/livy/repl_2.11-jars/livy-core_2.11-0.6.0-incubating.jar at spark://ip-10-0-3-246.eu-west-2.compute.internal:38251/jars/livy-core_2.11-0.6.0-incubating.jar with timestamp 1564570883198\n",
      "19/07/31 11:01:23 INFO SparkContext: Added JAR file:/usr/lib/livy/repl_2.11-jars/livy-repl_2.11-0.6.0-incubating.jar at spark://ip-10-0-3-246.eu-west-2.compute.internal:38251/jars/livy-repl_2.11-0.6.0-incubating.jar with timestamp 1564570883198\n",
      "19/07/31 11:01:23 INFO Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances\n",
      "19/07/31 11:01:24 INFO RMProxy: Connecting to ResourceManager at ip-10-0-3-246.eu-west-2.compute.internal/10.0.3.246:8032\n",
      "19/07/31 11:01:24 INFO Client: Requesting a new application from cluster with 30 NodeManagers\n",
      "19/07/31 11:01:24 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (12288 MB per container)\n",
      "19/07/31 11:01:24 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\n",
      "19/07/31 11:01:24 INFO Client: Setting up container launch context for our AM\n",
      "19/07/31 11:01:24 INFO Client: Setting up the launch environment for our AM container\n",
      "19/07/31 11:01:24 INFO Client: Preparing resources for our AM container\n",
      "19/07/31 11:01:24 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "19/07/31 11:01:27 INFO Client: Uploading resource file:/mnt/tmp/spark-e2505e50-fff3-4c0a-8f42-a80c730ca2d3/__spark_libs__3785820147383706962.zip -> hdfs://ip-10-0-3-246.eu-west-2.compute.internal:8020/user/livy/.sparkStaging/application_1564565932924_0004/__spark_libs__3785820147383706962.zip\n",
      "19/07/31 11:01:29 INFO Client: Uploading resource file:/usr/lib/livy/rsc-jars/netty-all-4.0.37.Final.jar -> hdfs://ip-10-0-3-246.eu-west-2.compute.internal:8020/user/livy/.sparkStaging/application_1564565932924_0004/netty-all-4.0.37.Final.jar\n",
      "19/07/31 11:01:29 INFO Client: Uploading resource file:/usr/lib/livy/rsc-jars/livy-api-0.6.0-incubating.jar -> hdfs://ip-10-0-3-246.eu-west-2.compute.internal:8020/user/livy/.sparkStaging/application_1564565932924_0004/livy-api-0.6.0-incubating.jar\n",
      "19/07/31 11:01:29 INFO Client: Uploading resource file:/usr/lib/livy/rsc-jars/livy-rsc-0.6.0-incubating.jar -> hdfs://ip-10-0-3-246.eu-west-2.compute.internal:8020/user/livy/.sparkStaging/application_1564565932924_0004/livy-rsc-0.6.0-incubating.jar\n",
      "19/07/31 11:01:29 INFO Client: Uploading resource file:/usr/lib/livy/repl_2.11-jars/commons-codec-1.9.jar -> hdfs://ip-10-0-3-246.eu-west-2.compute.internal:8020/user/livy/.sparkStaging/application_1564565932924_0004/commons-codec-1.9.jar\n",
      "19/07/31 11:01:29 INFO Client: Uploading resource file:/usr/lib/livy/repl_2.11-jars/livy-core_2.11-0.6.0-incubating.jar -> hdfs://ip-10-0-3-246.eu-west-2.compute.internal:8020/user/livy/.sparkStaging/application_1564565932924_0004/livy-core_2.11-0.6.0-incubating.jar\n",
      "19/07/31 11:01:29 INFO Client: Uploading resource file:/usr/lib/livy/repl_2.11-jars/livy-repl_2.11-0.6.0-incubating.jar -> hdfs://ip-10-0-3-246.eu-west-2.compute.internal:8020/user/livy/.sparkStaging/application_1564565932924_0004/livy-repl_2.11-0.6.0-incubating.jar\n",
      "19/07/31 11:01:29 INFO Client: Uploading resource file:/usr/lib/spark/R/lib/sparkr.zip#sparkr -> hdfs://ip-10-0-3-246.eu-west-2.compute.internal:8020/user/livy/.sparkStaging/application_1564565932924_0004/sparkr.zip\n",
      "19/07/31 11:01:29 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-10-0-3-246.eu-west-2.compute.internal:8020/user/livy/.sparkStaging/application_1564565932924_0004/pyspark.zip\n",
      "19/07/31 11:01:30 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://ip-10-0-3-246.eu-west-2.compute.internal:8020/user/livy/.sparkStaging/application_1564565932924_0004/py4j-0.10.7-src.zip\n",
      "19/07/31 11:01:30 WARN Client: Same name resource file:///usr/lib/spark/python/lib/pyspark.zip added multiple times to distributed cache\n",
      "19/07/31 11:01:30 WARN Client: Same name resource file:///usr/lib/spark/python/lib/py4j-0.10.7-src.zip added multiple times to distributed cache\n",
      "19/07/31 11:01:30 INFO Client: Uploading resource file:/mnt/tmp/spark-e2505e50-fff3-4c0a-8f42-a80c730ca2d3/__spark_conf__6355177106860051387.zip -> hdfs://ip-10-0-3-246.eu-west-2.compute.internal:8020/user/livy/.sparkStaging/application_1564565932924_0004/__spark_conf__.zip\n",
      "19/07/31 11:01:30 INFO SecurityManager: Changing view acls to: livy\n",
      "19/07/31 11:01:30 INFO SecurityManager: Changing modify acls to: livy\n",
      "19/07/31 11:01:30 INFO SecurityManager: Changing view acls groups to: \n",
      "19/07/31 11:01:30 INFO SecurityManager: Changing modify acls groups to: \n",
      "19/07/31 11:01:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(livy); groups with view permissions: Set(); users  with modify permissions: Set(livy); groups with modify permissions: Set()\n",
      "19/07/31 11:01:32 INFO Client: Submitting application application_1564565932924_0004 to ResourceManager\n",
      "19/07/31 11:01:32 INFO YarnClientImpl: Submitted application application_1564565932924_0004\n",
      "19/07/31 11:01:32 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1564565932924_0004 and attemptId None\n",
      "19/07/31 11:01:33 INFO Client: Application report for application_1564565932924_0004 (state: ACCEPTED)\n",
      "19/07/31 11:01:33 INFO Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: AM container is launched, waiting for AM container to Register with RM\n",
      "\t ApplicationMaster host: N/A\n",
      "\t ApplicationMaster RPC port: -1\n",
      "\t queue: default\n",
      "\t start time: 1564570892630\n",
      "\t final status: UNDEFINED\n",
      "\t tracking URL: http://ip-10-0-3-246.eu-west-2.compute.internal:20888/proxy/application_1564565932924_0004/\n",
      "\t user: livy\n",
      "19/07/31 11:01:34 INFO Client: Application report for application_1564565932924_0004 (state: ACCEPTED)\n",
      "19/07/31 11:01:35 INFO Client: Application report for application_1564565932924_0004 (state: ACCEPTED)\n",
      "19/07/31 11:01:36 INFO Client: Application report for application_1564565932924_0004 (state: ACCEPTED)\n",
      "19/07/31 11:01:37 INFO Client: Application report for application_1564565932924_0004 (state: ACCEPTED)\n",
      "19/07/31 11:01:38 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-10-0-3-246.eu-west-2.compute.internal, PROXY_URI_BASES -> http://ip-10-0-3-246.eu-west-2.compute.internal:20888/proxy/application_1564565932924_0004), /proxy/application_1564565932924_0004\n",
      "19/07/31 11:01:38 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.\n",
      "19/07/31 11:01:38 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\n",
      "19/07/31 11:01:38 INFO Client: Application report for application_1564565932924_0004 (state: RUNNING)\n",
      "19/07/31 11:01:38 INFO Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: N/A\n",
      "\t ApplicationMaster host: 10.0.3.195\n",
      "\t ApplicationMaster RPC port: -1\n",
      "\t queue: default\n",
      "\t start time: 1564570892630\n",
      "\t final status: UNDEFINED\n",
      "\t tracking URL: http://ip-10-0-3-246.eu-west-2.compute.internal:20888/proxy/application_1564565932924_0004/\n",
      "\t user: livy\n",
      "19/07/31 11:01:38 INFO YarnClientSchedulerBackend: Application application_1564565932924_0004 has started running.\n",
      "19/07/31 11:01:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37195.\n",
      "19/07/31 11:01:38 INFO NettyBlockTransferService: Server created on ip-10-0-3-246.eu-west-2.compute.internal:37195\n",
      "19/07/31 11:01:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "19/07/31 11:01:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-10-0-3-246.eu-west-2.compute.internal, 37195, None)\n",
      "19/07/31 11:01:38 INFO BlockManagerMasterEndpoint: Registering block manager ip-10-0-3-246.eu-west-2.compute.internal:37195 with 410.0 MB RAM, BlockManagerId(driver, ip-10-0-3-246.eu-west-2.compute.internal, 37195, None)\n",
      "19/07/31 11:01:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-10-0-3-246.eu-west-2.compute.internal, 37195, None)\n",
      "19/07/31 11:01:38 INFO BlockManager: external shuffle service port = 7337.\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "len(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Theta Capital Management', 'http://www.thetacapital.com', ' Theta Capital Management', 'html', 'Home\\n\\nAbout Us\\n\\n  \\n  \\n\\n# Theta Capital Management has been a leading provider of hedge fund solutions\\nsince 2001.\\n\\n## Our team of specialists have over 100 years of combined hedge fund\\nexperience which includes managing through the 2008 financial crisis. As\\nspecialists in hedge fund investing we have a deep understanding of the space\\nand focus on the areas where such strategies offer most added value and avoid\\nthe pitfalls unclear to non-dedicated investors.\\n\\nTheta Capital Management and shareholders are the largest investors, fully\\naligning ourselves with our investor base, which include family offices,\\ninstitutions, endowments and select individuals. The Theta approach has\\ntranslated into significant and consistent outperformance over time.\\n\\n##  A differentiating, value-added approach  \\n\\n#### Based on three pillars\\n\\n## Differentiated investments\\n\\nWe identify, analyse and access uniquely specialized investment strategies and\\ncombine them into portfolios with attractive and differentiating return\\nstreams\\n\\n## Optimized setup\\n\\nOur Individual Account setup up is specifically optimized for dealing with\\nhedge fund investments and making the most out of the structural advantages of\\nour client base\\n\\n## Partnership model\\n\\nWe work in close partnership with a small group of like-minded family offices,\\ninstitutions, endowments and select individuals that fit our investment\\napproach. Theta Capital has managed white-label solutions for clients since\\n2003. They provide organizations with an efficient hedge fund implementation\\nfor their clients while maintaining control and full transparency.\\n\\n## Theta Individual Accounts\\n\\n* * *\\n\\n### Large end-investors with a long investment horizon\\n\\nTheta Individual Accounts offer ownership, control and full transparency and\\ncan be tailored to an individual investor’s needs and preferences. The set-up\\nprovides the capital stability and synchronized expectations that have proven\\nto translate in superior long term performance.\\n\\n<div class=\"b\\n\\n')\n",
      "(' Theta Capital Management', 'http://www.thetacapital.com/?page_id=7', '  About us : Theta Capital Management', 'html', 'Home\\n\\nAbout Us\\n\\n  \\n  \\n\\n# About us\\n\\n## Theta Capital Management is the oldest and largest independent hedge fund\\nspecialist in The Netherlands.\\n\\nThe company was founded in 2001 with the goal to manage portfolios of hedge\\nfunds for clients. We believe that hedge funds provide the opportunity set,\\ninfrastructure and investment talent to deliver the best risk-reward\\nimplementation for any targeted risk profile. Theta Capital is based in\\nAmsterdam.\\n\\nTheta Capital Management is regulated by the Dutch regulator AFM and the Dutch\\nCentral Bank and holds an AIFMD license.\\n\\n# Our specialists\\n\\n## Tijo van Marle\\n\\n#### Founder\\n\\nTijo van Marle was a Managing Director at Credit Suisse in London and\\nAmsterdam before co-founding Theta in 2001. Prior to Credit Suisse, Tijo\\nworked at J. Henry Schroder Wagg & Co in London as Director International\\nCapital Markets (1972-1982) and in Hong Kong as Managing Director (1982-1984).\\nBefore that, he worked as an investment banker at Pierson, Heldring & Pierson\\nin Amsterdam (1967-1972). Tijo obtained a Master of Business Administration\\n(MBA) degree from the Harvard Business School in 1966.\\n\\n## Ruud Smets\\n\\n#### Partner - CIO\\n\\nRuud Smets joined Theta Capital Management in 2005 and has served as the\\nportfolio manager for the various hedge fund mandates since. Ruud has a broad\\ninvestment background with a specialization in hedge funds. Before joining\\nTheta, Ruud worked in interest rate derivatives sales and trading at NIBC\\nafter starting his career at FundPartners providing hedge fund solutions to\\ninstitutional investors. Ruud has obtained his master’s degrees in Investment\\nTheory and Information Technology from Tilburg University and La Trobe\\nUniverisity in 2002 and is a Chartered Alternative Investment Analyst.\\n\\n<img src=\"http://www.thetacapital.com/media/marc-\\n\\n')\n"
     ]
    }
   ],
   "source": [
    "for el in data1:\n",
    "    if \"http://www.thetacapital.com\" in el[1]:\n",
    "        print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crawl_df = spark.createDataFrame(df\n",
    "            .rdd\n",
    "            .mapPartitions(lambda u: run_spider(el.url for el in u))\n",
    "            , T.StructType([\n",
    "                T.StructField(\"website\", T.StringType()),\n",
    "                T.StructField(\"url\", T.StringType()),\n",
    "                T.StructField(\"page_title\", T.StringType()),\n",
    "                T.StructField(\"content_type\", T.StringType()),\n",
    "                T.StructField(\"raw_content\", T.StringType())\n",
    "            ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- website: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- page_title: string (nullable = true)\n",
      " |-- content_type: string (nullable = true)\n",
      " |-- raw_content: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "crawl_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d2aa16866343efb1e3a8d4b6462c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Error sending http request and maximum retry encountered.\n"
     ]
    }
   ],
   "source": [
    "(crawl_df\n",
    " .repartition(100)\n",
    " .write\n",
    " .parquet(\"s3://onai-ml-dev-eu-west-1/web_crawler/data/urls_and_content\", mode=\"overwrite\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst = spark.read.load(\"s3://onai-ml-dev-eu-west-1/web_crawler/data/urls_and_content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+--------------------+-----------------------------------+------------+-------------------------------+\n",
      "|                            website|                 url|                         page_title|content_type|                    raw_content|\n",
      "+-----------------------------------+--------------------+-----------------------------------+------------+-------------------------------+\n",
      "|           东华工程科技股份有限公司|http://www.chinae...|                              about|        html|           |\n",
      "\n",
      "|  |\n",
      "\n",
      "Chinese ...|\n",
      "|六合开奖记录-六合开奖结果-今晚六...|http://www.amerir...|     联系我们-六合开奖结果- Powe...|        html|      #\n",
      "\n",
      "  * 设为主页\n",
      "  * 加...|\n",
      "|                           怡球集团|http://www.yechiu...|                                   |        html|   股票代码601388\n",
      "\n",
      "简体中文 ...|\n",
      "|                         RealEnergy|http://www.realen...|                 Board of Directors|        html|                             \n",
      "\n",
      "|\n",
      "|                             heerim|http://www.heerim...|                             heerim|        html|         # heerim\n",
      "\n",
      "메뉴\n",
      "\n",
      "KOR...|\n",
      "|                                JWI|http://www.jwi.or...|                    About JWI — JWI|        html|                              \n",
      "|\n",
      "|                 Home – IMS Imaging|http://www.imsima...|               Contact Us – IMS ...|        html|                              \n",
      "|\n",
      "|                           hsdc.com| http://www.hsdc.com|                           hsdc.com|        html|     ###  \n",
      "\n",
      "|\n",
      "\n",
      "您访问的域名 ...|\n",
      "|   \r\n",
      "\tトップページ｜クリエイトSD...|http://www.create...|   \r\n",
      "\tトップページ｜クリエイトSD...|        html|           # <a id=\"dnn_dnnL...|\n",
      "|               Consumer Electron...|http://www.revena...|                               News|        html|           # Revena HDTV Wal...|\n",
      "|                                   |http://www.turnin...|                                   |        html|             \n",
      "Warning: Canno...|\n",
      "|                                   |http://www.baling...|                           服务中心|        html|    中文/English\n",
      "\n",
      "设为首页加...|\n",
      "|                       셀트리온제약|http://www.celltr...|                       셀트리온제약|        html|# 셀트리온제약 메인\n",
      "\n",
      "메인 메...|\n",
      "|               Home - Crystal St...|http://www.crysta...|               Ballston Quarter ...|        html|             * Home\n",
      "  * Serv...|\n",
      "|高新兴科技集团——智慧城市物联网产...|http://www.gosunc...|高新兴科技集团——智慧城市物联网产...|        html|      股票代码：300098\n",
      "\n",
      "Engl...|\n",
      "|高新兴科技集团——智慧城市物联网产...|http://www.gosunc...|高新兴科技集团——智慧城市物联网产...|        html|      股票代码：300098\n",
      "\n",
      "Engl...|\n",
      "|               Mining, Military ...|http://www.thorou...|               Mining, Military ...|        html|                              \n",
      "|\n",
      "|               \r\n",
      "\tTANTALUS RARE ...|http://www.tre-ag...|               \r\n",
      "\tOverview on Ra...|        html|           Skip to main cont...|\n",
      "|                Welcome to Randevoo|http://www.randev...|                Welcome to Randevoo|        html|           |  |\n",
      "\n",
      "MAXIMIZE EF...|\n",
      "|               Home - Ultra-safe...|http://www.ultra-...|               Home - Ultra-safe...|        html|                              \n",
      "|\n",
      "+-----------------------------------+--------------------+-----------------------------------+------------+-------------------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "tst.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8849"
     ]
    }
   ],
   "source": [
    "tst.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(tst\n",
    " .repartition(100)\n",
    " .write\n",
    " .parquet(\"s3://onai-ml-dev-eu-west-1/web_crawler/data/sample_urls_and_content\", mode=\"overwrite\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "* 10 urls per partition ~ 2 mins per partition: takes about 1.5 hrs to finish 10k urls\n",
    "* 100 urls per partition and config fixes: 21 minutes\n",
    "* 1000 urls per partition: 17 mins\n",
    "* looking only at main page and about, takes 8 mins 100 docs per partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
