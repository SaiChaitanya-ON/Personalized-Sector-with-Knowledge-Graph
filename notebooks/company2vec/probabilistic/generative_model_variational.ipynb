{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from simulator import generate_companies\n",
    "\n",
    "from scipy.special import psi\n",
    "from scipy.sparse import csr_matrix, hstack, lil_matrix, vstack\n",
    "\n",
    "from gensim.matutils import mean_absolute_difference\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_p_topic = 5\n",
    "industries = [\"pbc\", \"rubber\", \"media\"]\n",
    "X, Z, company_industry, phi, phi_bg, word2id, id2word = generate_companies(industries, \n",
    "                                                                           words_p_topic=words_p_topic,\n",
    "                                                                           num_companies=100000,\n",
    "                                                                          )\n",
    "n_topics, n_words = phi.shape\n",
    "n_docs = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "2\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 1. 1. 5. 1. 0. 1. 1. 0. 2. 1. 0. 1.\n",
      " 0. 1. 0. 2. 2. 2. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 3. 0. 1. 1.\n",
      " 1. 1. 0. 2. 0. 2. 1. 0. 1. 0. 3. 1. 2. 1. 3. 0. 1. 0. 1. 1. 0. 1. 1. 0.\n",
      " 3. 3. 2. 1. 0. 1. 1. 0. 1. 0. 1. 5. 1. 0. 3. 0. 0. 2. 0. 0. 1. 1. 2. 2.\n",
      " 0. 1. 0. 3. 0. 0. 0. 0. 2. 0. 3. 0. 0. 0. 0. 0. 4. 0. 1.]\n",
      "[2. 0. 1. 1. 5.]\n"
     ]
    }
   ],
   "source": [
    "ind = 0\n",
    "print(Z[ind])\n",
    "print(company_industry[ind])\n",
    "print(X.toarray()[ind,:])\n",
    "print(X.toarray()[ind,(words_p_topic*company_industry[ind]):(words_p_topic*(company_industry[ind]+1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .master(\"local[*]\")\n",
    "         .appName(\"SparkTest\")\n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLDA:\n",
    "    def __init__(self, word2id, \n",
    "                 industries, \n",
    "                 a=1.0, \n",
    "                 b=1.0, \n",
    "                 e_step_iter=50,\n",
    "                 print_every=25,\n",
    "                 estep_threshold=1e-5\n",
    "                ):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.estep_threshold = estep_threshold\n",
    "        \n",
    "        self.word2id = word2id\n",
    "        self.industries = industries\n",
    "        id2word = {}\n",
    "        for k,v in word2id.items():\n",
    "            id2word[v] = k\n",
    "        self.id2word = id2word\n",
    "        self.e_step_iter = e_step_iter\n",
    "        self.print_every = print_every\n",
    "    \n",
    "    def _e_step(self, X, metadata):\n",
    "        import numpy\n",
    "        from scipy.special import psi\n",
    "        from scipy.sparse import csr_matrix, hstack, lil_matrix, vstack\n",
    "        \n",
    "        a,b = self.a, self.b\n",
    "        D,V = X.shape\n",
    "        q_theta = np.random.gamma(1.0, size=(D,2))\n",
    "        q_z = lil_matrix((D,V))\n",
    "        phi = self.phi\n",
    "\n",
    "        for industry in range(len(self.industries)):\n",
    "            ind = metadata==industry\n",
    "            q_theta_ind = q_theta[ind,:]\n",
    "            X_ind = X[ind]\n",
    "            q_z_ind = lil_matrix(X_ind.shape)\n",
    "            d,v = X_ind.nonzero()\n",
    "            q_theta_ind_old = q_theta_ind.copy()\n",
    "            \n",
    "            for i in range(self.e_step_iter):\n",
    "                # Compute q(z)\n",
    "                coef = np.clip(psi(q_theta_ind[d,-1])-psi(np.sum(q_theta_ind[d], axis=1)), a_min=-100.0, a_max=100.0)\n",
    "                \n",
    "                bg_w = np.exp(coef)*phi[-1,v]\n",
    "                ind_w = np.exp(-coef)*phi[industry,v]\n",
    "                q_z_ind[d,v] = bg_w/(bg_w+ind_w+1e-9)\n",
    "\n",
    "                # Compute q(theta)\n",
    "                q_theta_ind[:,0] = a+np.sum(q_z_ind.multiply(X_ind), axis=1).ravel()\n",
    "                q_theta_ind[:,1] = b+np.sum(X_ind-q_z_ind.multiply(X_ind), axis=1).ravel()\n",
    "                \n",
    "                if mean_absolute_difference(q_theta_ind.ravel(), q_theta_ind_old.ravel()) <= self.estep_threshold:\n",
    "                    break\n",
    "                q_theta_ind_old = q_theta_ind.copy()\n",
    "\n",
    "            q_z[ind] = q_z_ind\n",
    "            q_theta[ind] = q_theta_ind\n",
    "        \n",
    "        return q_z, q_theta\n",
    "    \n",
    "    def _m_step(self, X, q_z, metadata):\n",
    "        import numpy\n",
    "        from scipy.special import psi\n",
    "        from scipy.sparse import csr_matrix, hstack, lil_matrix, vstack\n",
    "        \n",
    "        industries = self.industries\n",
    "        id2word = self.id2word\n",
    "        _sstats = np.zeros(shape=(len(industries)+1, len(id2word)))\n",
    "\n",
    "        for industry in range(len(industries)):\n",
    "            ind = metadata==industry\n",
    "            q_z_ind = q_z[ind]\n",
    "            X_ind = X[ind]\n",
    "            mlt = q_z_ind.multiply(X_ind)\n",
    "            q_z_sm_bg = np.sum(mlt, axis=0)\n",
    "            q_z_sm_ind = np.sum(X_ind - mlt, axis=0)\n",
    "\n",
    "            # Background sstats\n",
    "            _sstats[-1,:] = _sstats[-1,:] + q_z_sm_bg\n",
    "\n",
    "            # Industry sstats\n",
    "            _sstats[industry,:] = _sstats[industry,:] + q_z_sm_ind\n",
    "        \n",
    "        return _sstats\n",
    "        \n",
    "    def _update_phi(self):\n",
    "        self.phi = self._sstats/np.sum(self._sstats, axis=1, keepdims=True)\n",
    "        self._sstats = np.zeros(shape=(len(self.industries)+1, len(self.id2word)))\n",
    "\n",
    "    def train(self, X, metadata, n_iter=50):\n",
    "        industries = self.industries\n",
    "        id2word = self.id2word\n",
    "        self._sstats = np.zeros(shape=(len(industries)+1, len(id2word)))\n",
    "        self.phi = np.random.dirichlet([1.0]*(len(id2word)), size=(len(industries)+1))\n",
    "\n",
    "        for i in range(n_iter):\n",
    "            if i%self.print_every == 0:\n",
    "                print(i)\n",
    "            q_z,_ = self._e_step(X, metadata)\n",
    "            self._sstats = self._m_step(X, q_z, metadata)\n",
    "            self._update_phi()\n",
    "            \n",
    "    def train_distributed(self, X_metadata_rdd, n_iter=50):\n",
    "        industries = self.industries\n",
    "        id2word = self.id2word\n",
    "        self._sstats = np.zeros(shape=(len(industries)+1, len(id2word)))\n",
    "        self.phi = np.random.dirichlet([1.0]*(len(id2word)), size=(len(industries)+1))\n",
    "        \n",
    "        for i in range(n_iter):\n",
    "            print(i)\n",
    "            self._sstats = (X_metadata_rdd\n",
    "                             .mapPartitions(lambda u: [list(u)])\n",
    "                             .map(lambda u: (vstack([el[0] for el in u], format=\"lil\"), \n",
    "                                             np.array([el[1] for el in u])\n",
    "                                             )\n",
    "                                  )\n",
    "                             .map(lambda line: (line[0], line[1], self._e_step(line[0], line[1])))\n",
    "                             .map(lambda line: self._m_step(line[0], line[2][0], line[1]))\n",
    "                             .reduce(lambda a,b: a+b)\n",
    "                            )\n",
    "            self._update_phi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = SimpleLDA(word2id, industries, e_step_iter=50, print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "tst.train(X, np.array(company_industry), n_iter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_metadata_rdd = spark.sparkContext.parallelize(list(zip(X,company_industry)), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.train_distributed(X_metadata_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "q_z, q_theta = tst._e_step(X, np.array(company_industry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst._m_step(X, q_z, np.array(company_industry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst._update_phi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind=9\n",
    "Z[ind]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16203939683294755"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha, beta = q_theta[ind]\n",
    "(alpha-1)/(alpha+beta-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_topics(model):\n",
    "    phi = model.phi\n",
    "    id2word = model.id2word\n",
    "\n",
    "    for i,topic in enumerate(phi):\n",
    "        topic_name = model.industries[i] if i < len(model.industries) else \"background\"\n",
    "        print(\"#\"*20, topic_name, \"#\"*20)\n",
    "        for prob,i in islice(sorted([(prob,i) for i,prob in enumerate(topic)], reverse=True), 20):\n",
    "            print(f\"{id2word[i]}:{prob} \", end=\"\")\n",
    "        print()\n",
    "        print(\"#\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### pbc ####################\n",
      "pbc_word_4:0.07534915206131437 pbc_word_0:0.058010320558367745 pbc_word_1:0.03995175223929919 pbc_word_3:0.033103261374531845 pbc_word_2:0.02876636046517686 background_word_66:0.022131855208278744 background_word_9:0.02167824945386023 background_word_4:0.021507901615137017 background_word_60:0.020116755735080708 background_word_74:0.01854155487978196 background_word_97:0.01586223407996577 background_word_99:0.014991985130582744 background_word_80:0.014073735303582245 background_word_89:0.012785135468585946 background_word_84:0.012635328702914641 background_word_47:0.012228231119423946 background_word_29:0.012099746867287525 background_word_82:0.011961562089294586 background_word_22:0.01170929831443301 background_word_67:0.011591268913134079 \n",
      "################################################################################\n",
      "#################### rubber ####################\n",
      "rubber_word_0:0.05292214429586776 rubber_word_3:0.05140293818137645 rubber_word_1:0.04357764150511411 rubber_word_2:0.03140719223635807 rubber_word_4:0.025238754435128827 background_word_15:0.022815875459085175 background_word_34:0.01971618564484144 background_word_6:0.01939526817088789 background_word_70:0.019188174578565306 background_word_51:0.018124569128851287 background_word_73:0.018088075186141982 background_word_93:0.018079146105322283 background_word_19:0.016772105778465024 background_word_36:0.016526302066532682 background_word_54:0.01564443496358823 background_word_60:0.013933020553935032 media_word_0:0.013844168935917124 pbc_word_0:0.01375354787243471 background_word_29:0.013226040693812106 background_word_9:0.01294343441383079 \n",
      "################################################################################\n",
      "#################### media ####################\n",
      "media_word_4:0.07167726753726446 media_word_0:0.050017471332820355 background_word_74:0.04302432836698753 media_word_3:0.0343714277723092 media_word_2:0.032856110500128564 media_word_1:0.02955066628541864 background_word_43:0.020246844299828478 background_word_68:0.01901555476392696 background_word_69:0.01757282697624561 background_word_47:0.01596956217044034 background_word_65:0.014279312386497017 background_word_86:0.014202967769305169 background_word_67:0.01376401475316885 background_word_24:0.013735703570264312 background_word_93:0.013671347616321492 background_word_12:0.013652427939857478 background_word_82:0.013071962005412758 background_word_15:0.01288791745406145 background_word_88:0.012844869243333234 background_word_13:0.012824646031865068 \n",
      "################################################################################\n",
      "#################### background ####################\n",
      "background_word_57:0.03217951771719 background_word_44:0.026048852674336223 background_word_99:0.024868758641448555 background_word_80:0.023800631789339378 background_word_40:0.02082589327855474 background_word_48:0.020799036522045736 background_word_81:0.02015696315332419 background_word_58:0.020140081098220165 background_word_10:0.019818254262217543 background_word_59:0.01970784006424737 background_word_49:0.01968348279931721 background_word_71:0.019035743737628136 background_word_63:0.018908700241426962 background_word_14:0.01889943198063441 background_word_66:0.018669529483356012 background_word_73:0.017609098292569108 background_word_98:0.017448678214183062 background_word_92:0.017386151251667717 background_word_68:0.017082953483811652 background_word_33:0.015993295121115067 \n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "plot_topics(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.77360101e-04, 5.08047892e-09, 4.95699909e-09, 5.95946442e-09,\n",
       "       4.45524698e-09, 1.06981330e-08, 1.23745819e-08, 3.50080409e-03,\n",
       "       4.46296889e-09, 1.95095651e-03, 5.05757351e-02, 4.23133669e-02,\n",
       "       5.21601942e-02, 6.52181788e-02, 2.88467847e-02, 1.39022941e-02,\n",
       "       4.11016556e-03, 7.69024571e-06, 4.85166323e-03, 1.43319551e-02,\n",
       "       2.85845865e-03, 1.14937039e-02, 5.81033200e-03, 4.51968913e-04,\n",
       "       9.11293664e-03, 4.82247234e-03, 4.15702485e-03, 1.19372560e-02,\n",
       "       1.20693406e-02, 1.45752363e-02, 3.54375647e-03, 1.22369497e-02,\n",
       "       1.39254050e-03, 1.20255880e-02, 8.62462024e-03, 7.72820938e-03,\n",
       "       6.64722434e-03, 5.29770320e-03, 6.86598470e-03, 7.68281416e-04,\n",
       "       8.96557302e-04, 8.97453427e-03, 1.34233474e-02, 1.43754160e-02,\n",
       "       2.05959709e-02, 7.59492367e-03, 7.88963925e-03, 2.29643447e-03,\n",
       "       1.12868267e-04, 3.63032997e-03, 1.05711903e-02, 8.55567312e-03,\n",
       "       8.01980738e-03, 5.58202900e-03, 1.20722750e-02, 1.38479580e-02,\n",
       "       6.78894398e-03, 8.14519980e-03, 7.17141041e-03, 5.00984280e-03,\n",
       "       1.06818913e-02, 7.45486999e-04, 1.85560968e-08, 4.23256058e-03,\n",
       "       6.55530148e-03, 1.10538228e-02, 1.25054275e-02, 1.05536438e-02,\n",
       "       4.43688848e-04, 4.73904411e-03, 2.60544643e-03, 4.35561720e-03,\n",
       "       7.98854898e-03, 8.33027909e-03, 8.31223779e-03, 7.65684106e-03,\n",
       "       6.20859390e-03, 2.03046274e-03, 7.48884507e-03, 8.91496768e-03,\n",
       "       3.66231696e-03, 6.08170970e-03, 5.90950468e-03, 5.68676979e-03,\n",
       "       7.23531761e-03, 1.12348718e-02, 3.38043432e-03, 1.07734173e-02,\n",
       "       6.30679212e-03, 6.77056137e-03, 1.95010474e-02, 6.14163941e-03,\n",
       "       9.39468227e-05, 3.16009977e-03, 1.53307125e-02, 7.59318794e-03,\n",
       "       5.50079215e-03, 8.85943590e-03, 4.96282540e-03, 6.88854688e-03,\n",
       "       6.18775124e-03, 1.06612439e-02, 7.58630446e-03, 7.17221036e-03,\n",
       "       1.95268696e-07, 5.69251259e-03, 1.32980553e-02, 1.26597461e-02,\n",
       "       9.93755024e-03, 4.17347698e-03, 6.63000031e-03, 2.95830290e-02,\n",
       "       1.01677100e-02, 1.21569561e-02, 3.39546640e-03])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst.phi[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00255062, 0.00374005, 0.00143705, 0.01602743, 0.00730041,\n",
       "       0.00575224, 0.01068066, 0.00208225, 0.00461285, 0.00737695,\n",
       "       0.00445051, 0.01031931, 0.00862009, 0.00426616, 0.00575331,\n",
       "       0.00270197, 0.01428479, 0.01895589, 0.0069042 , 0.00038038,\n",
       "       0.00566887, 0.00488394, 0.00657537, 0.0221984 , 0.0174086 ,\n",
       "       0.00028983, 0.01210961, 0.01028605, 0.00820914, 0.01900917,\n",
       "       0.01156574, 0.00867146, 0.01760637, 0.01293167, 0.00373843,\n",
       "       0.00449055, 0.01899139, 0.01627245, 0.00764862, 0.01483029,\n",
       "       0.02352811, 0.01402309, 0.00346546, 0.00026798, 0.00638356,\n",
       "       0.00831331, 0.00132077, 0.00892662, 0.01900948, 0.01524567,\n",
       "       0.00753582, 0.00454427, 0.00617305, 0.00258613, 0.00291366,\n",
       "       0.00991292, 0.00859201, 0.00969812, 0.00317606, 0.0101634 ,\n",
       "       0.01005122, 0.01480652, 0.01329156, 0.00498139, 0.00473017,\n",
       "       0.00881681, 0.00245789, 0.01447389, 0.01531067, 0.00529541,\n",
       "       0.01432582, 0.0075923 , 0.00063904, 0.01877674, 0.00335549,\n",
       "       0.00224904, 0.00082259, 0.01138058, 0.00056275, 0.00268091,\n",
       "       0.01365238, 0.00017924, 0.01328653, 0.00322912, 0.00792621,\n",
       "       0.01542978, 0.00520373, 0.00387177, 0.00115497, 0.01593403,\n",
       "       0.01873756, 0.00433405, 0.01741299, 0.02083968, 0.01573822,\n",
       "       0.00459571, 0.0035887 , 0.01104372, 0.01087736, 0.0090598 ,\n",
       "       0.00507087, 0.00689576, 0.00597247, 0.00488215, 0.01196422,\n",
       "       0.01837637, 0.01155199, 0.00746727, 0.00281665, 0.00062155,\n",
       "       0.00031126, 0.011951  , 0.00382499, 0.01225614, 0.01597839])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst.phi[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009806433896111504"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst.phi[-1, 33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'pbc_word_0',\n",
       " 1: 'pbc_word_1',\n",
       " 2: 'pbc_word_2',\n",
       " 3: 'pbc_word_3',\n",
       " 4: 'pbc_word_4',\n",
       " 5: 'rubber_word_0',\n",
       " 6: 'rubber_word_1',\n",
       " 7: 'rubber_word_2',\n",
       " 8: 'rubber_word_3',\n",
       " 9: 'rubber_word_4',\n",
       " 10: 'media_word_0',\n",
       " 11: 'media_word_1',\n",
       " 12: 'media_word_2',\n",
       " 13: 'media_word_3',\n",
       " 14: 'media_word_4',\n",
       " 15: 'background_word_0',\n",
       " 16: 'background_word_1',\n",
       " 17: 'background_word_2',\n",
       " 18: 'background_word_3',\n",
       " 19: 'background_word_4',\n",
       " 20: 'background_word_5',\n",
       " 21: 'background_word_6',\n",
       " 22: 'background_word_7',\n",
       " 23: 'background_word_8',\n",
       " 24: 'background_word_9',\n",
       " 25: 'background_word_10',\n",
       " 26: 'background_word_11',\n",
       " 27: 'background_word_12',\n",
       " 28: 'background_word_13',\n",
       " 29: 'background_word_14',\n",
       " 30: 'background_word_15',\n",
       " 31: 'background_word_16',\n",
       " 32: 'background_word_17',\n",
       " 33: 'background_word_18',\n",
       " 34: 'background_word_19',\n",
       " 35: 'background_word_20',\n",
       " 36: 'background_word_21',\n",
       " 37: 'background_word_22',\n",
       " 38: 'background_word_23',\n",
       " 39: 'background_word_24',\n",
       " 40: 'background_word_25',\n",
       " 41: 'background_word_26',\n",
       " 42: 'background_word_27',\n",
       " 43: 'background_word_28',\n",
       " 44: 'background_word_29',\n",
       " 45: 'background_word_30',\n",
       " 46: 'background_word_31',\n",
       " 47: 'background_word_32',\n",
       " 48: 'background_word_33',\n",
       " 49: 'background_word_34',\n",
       " 50: 'background_word_35',\n",
       " 51: 'background_word_36',\n",
       " 52: 'background_word_37',\n",
       " 53: 'background_word_38',\n",
       " 54: 'background_word_39',\n",
       " 55: 'background_word_40',\n",
       " 56: 'background_word_41',\n",
       " 57: 'background_word_42',\n",
       " 58: 'background_word_43',\n",
       " 59: 'background_word_44',\n",
       " 60: 'background_word_45',\n",
       " 61: 'background_word_46',\n",
       " 62: 'background_word_47',\n",
       " 63: 'background_word_48',\n",
       " 64: 'background_word_49',\n",
       " 65: 'background_word_50',\n",
       " 66: 'background_word_51',\n",
       " 67: 'background_word_52',\n",
       " 68: 'background_word_53',\n",
       " 69: 'background_word_54',\n",
       " 70: 'background_word_55',\n",
       " 71: 'background_word_56',\n",
       " 72: 'background_word_57',\n",
       " 73: 'background_word_58',\n",
       " 74: 'background_word_59',\n",
       " 75: 'background_word_60',\n",
       " 76: 'background_word_61',\n",
       " 77: 'background_word_62',\n",
       " 78: 'background_word_63',\n",
       " 79: 'background_word_64',\n",
       " 80: 'background_word_65',\n",
       " 81: 'background_word_66',\n",
       " 82: 'background_word_67',\n",
       " 83: 'background_word_68',\n",
       " 84: 'background_word_69',\n",
       " 85: 'background_word_70',\n",
       " 86: 'background_word_71',\n",
       " 87: 'background_word_72',\n",
       " 88: 'background_word_73',\n",
       " 89: 'background_word_74',\n",
       " 90: 'background_word_75',\n",
       " 91: 'background_word_76',\n",
       " 92: 'background_word_77',\n",
       " 93: 'background_word_78',\n",
       " 94: 'background_word_79',\n",
       " 95: 'background_word_80',\n",
       " 96: 'background_word_81',\n",
       " 97: 'background_word_82',\n",
       " 98: 'background_word_83',\n",
       " 99: 'background_word_84',\n",
       " 100: 'background_word_85',\n",
       " 101: 'background_word_86',\n",
       " 102: 'background_word_87',\n",
       " 103: 'background_word_88',\n",
       " 104: 'background_word_89',\n",
       " 105: 'background_word_90',\n",
       " 106: 'background_word_91',\n",
       " 107: 'background_word_92',\n",
       " 108: 'background_word_93',\n",
       " 109: 'background_word_94',\n",
       " 110: 'background_word_95',\n",
       " 111: 'background_word_96',\n",
       " 112: 'background_word_97',\n",
       " 113: 'background_word_98',\n",
       " 114: 'background_word_99'}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst.id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
