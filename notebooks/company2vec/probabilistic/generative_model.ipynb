{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from simulator import generate_companies\n",
    "from theano import shared\n",
    "import theano.tensor as tt\n",
    "\n",
    "import pymc3 as pm\n",
    "from pymc3 import math as pmmath\n",
    "from pymc3 import Beta, Dirichlet\n",
    "from pymc3.distributions.transforms import t_stick_breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "theano.config.compute_test_value = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_p_topic = 5\n",
    "industries = [\"pbc\", \"rubber\", \"media\"]\n",
    "X, Z, company_industry, phi, phi_bg, word2id, id2word = generate_companies(industries, \n",
    "                                                                           words_p_topic=words_p_topic\n",
    "                                                                          )\n",
    "n_topics, n_words = phi.shape\n",
    "n_docs = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "0\n",
      "[8. 2. 4. 4. 4. 0. 0. 2. 1. 0. 0. 1. 0. 1. 1. 1. 2. 0. 1. 1. 1. 0. 1. 1.\n",
      " 0. 0. 0. 0. 2. 1. 3. 0. 0. 3. 0. 0. 0. 1. 1. 1. 0. 0. 0. 3. 0. 1. 0. 1.\n",
      " 0. 0. 0. 1. 1. 1. 0. 2. 0. 0. 1. 1. 2. 1. 0. 2. 2. 2. 1. 1. 1. 1. 0. 0.\n",
      " 2. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 2. 0. 1. 1. 1. 1.\n",
      " 1. 1. 3. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1.]\n",
      "[8. 2. 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "ind = 0\n",
    "print(Z[ind])\n",
    "print(company_industry[ind])\n",
    "print(X.toarray()[ind,:])\n",
    "print(X.toarray()[ind,(words_p_topic*company_industry[ind]):(words_p_topic*(company_industry[ind]+1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = np.array(company_industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logp_generator(phi, theta):\n",
    "    def logp_docs(docs_industry):\n",
    "        docs = docs_industry[:,:n_words]\n",
    "        industry = docs_industry[:,n_words:]\n",
    "        ll_docs  = 0\n",
    "        for ind in range(len(industries)):\n",
    "            industry_ind = tt.eq(industry, ind).ravel()\n",
    "            docs_ind = docs[industry_ind,:]\n",
    "            d,v = docs_ind.nonzero()\n",
    "            w = docs_ind[d,v]\n",
    "            ll_docs += tt.sum(w*pmmath.logsumexp(tt.log(phi[[ind,-1],:].T[v]) + tt.log(theta[industry_ind][d]), axis=1).ravel())\n",
    "        return ll_docs\n",
    "    \n",
    "    return logp_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_industry_t = tt.concatenate([X.toarray(), np.array(company_industry)[:, np.newaxis]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/opt/conda/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/opt/conda/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/opt/conda/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/opt/conda/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    phi = Dirichlet('phi', a=pm.floatX((1.0 / (n_topics+1)) * np.ones((n_topics+1, n_words))),\n",
    "                     shape=(n_topics+1, n_words) # last topic is by default the background topic\n",
    "                    )\n",
    "    theta = Dirichlet('theta', a=pm.floatX((1.0 / 2) * np.ones((n_docs, 2))),\n",
    "                      shape=(n_docs, 2)\n",
    "                      )\n",
    "    doc = pm.DensityDist('doc', logp_generator(phi, theta), observed=doc_industry_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "/opt/conda/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/opt/conda/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/opt/conda/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Multiprocess sampling (2 chains in 3 jobs)\n",
      "NUTS: [theta, phi]\n",
      "Sampling 2 chains:   0%|          | 0/2500 [00:00<?, ?draws/s]/opt/conda/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/opt/conda/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Sampling 2 chains: 100%|██████████| 2500/2500 [20:21<00:00,  2.05draws/s] \n",
      "There were 49 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 21 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "    trace = pm.sample(750, chains=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples_topics(trace):\n",
    "    tr = trace.get_values(\"phi\", combine=False)[0]\n",
    "    phi = np.mean(tr, axis=0)\n",
    "    for topic in phi:\n",
    "        for prob,i in sorted([(prob,i) for i,prob in enumerate(topic)], reverse=True):\n",
    "            print(f\"{id2word[i]}:{prob} \", end=\"\")\n",
    "        print()\n",
    "        print(\"#\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pbc_word_0:0.10055565894279138 pbc_word_3:0.07638881477352504 pbc_word_4:0.07034518968766654 pbc_word_1:0.06495384769644433 pbc_word_2:0.05994793142213591 background_word_32:0.043739503330072635 background_word_91:0.030479783253153214 background_word_56:0.024330591842324827 background_word_81:0.02260019982842373 background_word_50:0.02060684613386145 background_word_89:0.019195158290517975 rubber_word_1:0.018529904362692275 background_word_51:0.014143636889154411 rubber_word_2:0.013140653788888691 background_word_39:0.012481513419963258 background_word_90:0.012323029858903546 background_word_63:0.011357176790802052 background_word_84:0.011181283073573927 background_word_34:0.01109525797252815 background_word_10:0.011092636688053242 media_word_3:0.011005945774161058 background_word_38:0.010490088353044057 background_word_35:0.010202840128425886 background_word_0:0.010041241410522648 background_word_72:0.009926985146410912 background_word_5:0.009593885238840366 background_word_4:0.009312043799330573 background_word_83:0.008952398554391377 background_word_68:0.008489826297698056 background_word_22:0.008325501585841805 background_word_28:0.008169250719327377 background_word_1:0.007793035714517714 background_word_3:0.007607593911349886 background_word_44:0.007480841260560216 background_word_88:0.007047830933114691 background_word_75:0.007026972217654394 background_word_21:0.0069869654827063536 background_word_61:0.006760796582057195 media_word_2:0.0067188378107055895 background_word_52:0.006411790174117917 background_word_99:0.0063982601321404325 rubber_word_0:0.006329436309967834 background_word_20:0.006074840236941206 rubber_word_3:0.005716410431573561 background_word_95:0.005108786606411623 background_word_31:0.004923870240745089 background_word_59:0.004748988681679144 background_word_43:0.004651267609465154 background_word_14:0.0046192182679347235 background_word_29:0.004549997616404159 background_word_97:0.004461235167542635 background_word_27:0.0041651016107858915 background_word_57:0.004131497377276245 background_word_96:0.004119859067909426 background_word_71:0.004022699987961012 background_word_48:0.003988544293710475 background_word_94:0.0039750970616555 background_word_18:0.0038452623176816847 background_word_76:0.003791662774159672 background_word_16:0.003668109443670989 background_word_53:0.003641229344948731 background_word_86:0.003577290978304242 background_word_73:0.0035587071395992423 background_word_67:0.0034186544516629624 background_word_36:0.003317325338516099 background_word_78:0.003302082049761759 background_word_60:0.003221416212219556 background_word_17:0.0031269666147016413 background_word_8:0.003111207281516248 media_word_4:0.0029802014761464955 background_word_87:0.0029652300029163535 background_word_70:0.0028183947911603483 background_word_11:0.0027129948038312054 background_word_55:0.0026667490337236987 background_word_15:0.0026268450084838625 media_word_1:0.0025654527302674257 background_word_9:0.002422778348529487 background_word_13:0.0023709256064218314 background_word_79:0.0023053462781797824 media_word_0:0.0021775404337876342 background_word_69:0.0020541545260874838 background_word_80:0.0018040311927315417 background_word_42:0.0017878084087636487 background_word_23:0.0015892964301238593 background_word_45:0.0014871985882981926 background_word_40:0.001397021421132267 background_word_49:0.001383015883536578 background_word_2:0.0013341677789808454 background_word_12:0.0012638515874922815 background_word_85:0.0012140195905474024 background_word_98:0.0012082281512329359 background_word_82:0.0010723290833757335 background_word_30:0.0010688381644152886 background_word_93:0.0010635654230218108 background_word_24:0.0010554164078531725 background_word_46:0.000985793521382596 background_word_7:0.0009538105737885197 background_word_62:0.0008654591016456812 rubber_word_4:0.0008633829913877874 background_word_58:0.0008471716439823622 background_word_54:0.0008113702394904941 background_word_92:0.0007363463906925736 background_word_66:0.0007316891311575613 background_word_64:0.0006796534377821841 background_word_65:0.0005643712205966555 background_word_77:0.0003941548473087469 background_word_26:0.00033324537236599256 background_word_33:0.00029681847132940494 background_word_19:0.0002648432346817384 background_word_41:0.0002439402026361106 background_word_25:0.000198978077154513 background_word_6:0.00012864003581602968 background_word_47:0.00012149940215783883 background_word_74:0.00010392284568428955 background_word_37:8.119432081603739e-05 \n",
      "################################################################################\n",
      "rubber_word_4:0.11939653419018004 rubber_word_1:0.06226241314151297 rubber_word_0:0.055514515990813154 rubber_word_2:0.046888854899651194 rubber_word_3:0.04563300703962981 background_word_71:0.02880792255394033 background_word_57:0.026833459716846864 background_word_48:0.024817365264455285 background_word_52:0.019496668389002412 background_word_63:0.0166056910144884 background_word_18:0.014917725955275405 background_word_87:0.014672025582313765 background_word_26:0.014636359659200262 background_word_7:0.013863706336213283 pbc_word_2:0.013810626476444543 background_word_51:0.013403385760560393 background_word_32:0.01300482817105173 background_word_54:0.012911247426280366 pbc_word_1:0.012076428985597793 background_word_19:0.011965249751746296 background_word_85:0.011134065473655972 background_word_59:0.011126273662052908 background_word_80:0.010763712454622836 background_word_47:0.010597499437160844 background_word_45:0.010271172949851425 background_word_83:0.010029565399190967 background_word_98:0.00996738577713647 background_word_28:0.009762055365701763 background_word_55:0.009452692426005679 media_word_4:0.009118764556336907 background_word_62:0.008973944616263973 background_word_97:0.008845983629184795 background_word_35:0.00865380501648176 background_word_56:0.008636475260580576 background_word_30:0.008406390894264542 background_word_79:0.008377253786196847 background_word_68:0.008210251417763981 background_word_50:0.008107369386179031 background_word_1:0.00797633278890483 background_word_0:0.00792713648056611 background_word_53:0.007779019470914167 background_word_36:0.0075995497982120665 background_word_89:0.007594667969409889 background_word_37:0.007442507122184244 background_word_33:0.007291106057317835 background_word_75:0.00726652122389446 background_word_2:0.00713839252998477 background_word_58:0.007121227369417607 background_word_64:0.006903112121893001 background_word_27:0.00669686016568379 background_word_16:0.0064977723676201676 background_word_77:0.00648655192803202 background_word_92:0.006114874987181574 background_word_12:0.006023329948709233 background_word_78:0.005870949189143285 background_word_72:0.005626669000585517 background_word_82:0.005545526562643736 background_word_24:0.00517815974773678 background_word_34:0.005175959991167068 background_word_4:0.005164394620184436 background_word_65:0.004897024161735042 background_word_69:0.004430902245404678 background_word_22:0.0044233492899471176 background_word_96:0.00406122062102862 background_word_25:0.003971412347658733 background_word_93:0.00393244710831531 pbc_word_0:0.00358477902423063 background_word_60:0.0035653089091681866 background_word_42:0.0034988195431120434 background_word_39:0.0034634852831016043 background_word_15:0.002987746341333841 background_word_70:0.0028997189311134857 background_word_3:0.0028927431440715795 background_word_86:0.002863977797717044 background_word_10:0.0028298475070799877 background_word_31:0.002708810450145702 background_word_13:0.0027000117480149434 background_word_91:0.0026159441525744898 background_word_20:0.002492142265987235 background_word_61:0.002463652895810571 background_word_41:0.002433236700779949 background_word_21:0.002382550980912618 media_word_2:0.0021892593234397926 background_word_66:0.002165099666897608 background_word_38:0.0021270071594532217 background_word_99:0.002064273221067122 background_word_6:0.00205827051032193 background_word_23:0.002011032742701952 pbc_word_3:0.0018223101458001902 background_word_88:0.0016483361822549308 background_word_14:0.0015835531291975282 background_word_40:0.0015523000475009062 background_word_49:0.001078104067111794 background_word_84:0.0010435461145405713 background_word_44:0.0010183485204358388 pbc_word_4:0.0009430381112633124 background_word_94:0.0008152631497530924 background_word_81:0.0007353085234975308 background_word_8:0.0005248400802207451 background_word_74:0.0004470230204889006 background_word_67:0.0004431791560071559 background_word_43:0.00044071441912615667 background_word_46:0.00042680484304625 background_word_76:0.00031836116454923564 background_word_5:0.0003124658188846548 media_word_1:0.00026655137174570693 background_word_90:0.00024340304512529624 background_word_95:0.00022993046597560133 background_word_9:0.00022147335200645206 background_word_11:0.00020026701523412582 background_word_17:0.00019499488177980598 background_word_73:0.0001307300156272968 background_word_29:0.00011999379968215914 media_word_0:0.00011026306090694088 media_word_3:4.1523169890830694e-05 \n",
      "################################################################################\n",
      "media_word_1:0.12009236297350812 media_word_4:0.0759203185057075 media_word_2:0.04986638522972961 background_word_12:0.04108813314313634 media_word_3:0.04001228200146676 media_word_0:0.026604424405206942 background_word_87:0.023056518572232197 background_word_41:0.02284803294925247 background_word_16:0.019017710508207396 background_word_36:0.017593773464021772 background_word_81:0.015627774815091956 background_word_27:0.014720004698397966 rubber_word_4:0.013775205758411421 background_word_46:0.01373224001889746 background_word_20:0.013663732219096787 background_word_37:0.013596562565719984 background_word_68:0.013294367382537907 background_word_43:0.012837619439187348 background_word_73:0.012643354878607536 background_word_50:0.0126186874347317 background_word_61:0.012490938734673399 background_word_26:0.012224458520293552 background_word_96:0.012198655727799488 background_word_45:0.011501327878176247 background_word_65:0.011179845946369808 background_word_98:0.011139945243456578 background_word_2:0.010915243695619421 background_word_18:0.010675981098119939 background_word_13:0.010668903519406723 background_word_78:0.01058684834707279 background_word_47:0.009799656864997328 background_word_14:0.009593081721362952 background_word_28:0.009505922600095635 background_word_63:0.009178311898351504 pbc_word_0:0.00890095425384146 background_word_30:0.008859084495402037 background_word_69:0.008556440635498519 background_word_4:0.007624375812501667 background_word_24:0.007556579540423095 background_word_83:0.007445262526052138 background_word_97:0.007402716529243118 background_word_82:0.007211259699720609 rubber_word_1:0.007075028207469129 background_word_22:0.006902873729478449 background_word_72:0.0068440977230314675 background_word_21:0.00670482130013903 background_word_9:0.006682172184564325 background_word_70:0.006446095436547908 background_word_90:0.00638982985056329 background_word_44:0.006296207539665989 background_word_48:0.006122142353486234 background_word_91:0.005941591946501059 background_word_11:0.005931413951510542 background_word_42:0.005900054056959069 background_word_3:0.005710430660703395 background_word_58:0.005524779332193307 background_word_25:0.005491924424893253 rubber_word_2:0.004824243112259727 background_word_92:0.004820980699016748 background_word_5:0.004642838891607284 background_word_67:0.004525983560014546 background_word_80:0.00425377465470163 background_word_60:0.004006192470027056 background_word_64:0.003947807879812501 background_word_77:0.003810573077080224 background_word_8:0.003685977814384075 background_word_0:0.003664312574903807 background_word_40:0.003307937069832185 background_word_33:0.0031641183870817634 background_word_39:0.003002096079722516 background_word_10:0.002770184247952171 background_word_17:0.0026705981514257796 background_word_95:0.002594698308008901 background_word_62:0.0025860667065757516 pbc_word_1:0.002538723969462012 background_word_7:0.0025331562473051637 background_word_59:0.002455742394638319 background_word_35:0.002382022552426747 background_word_74:0.002346266160686107 background_word_15:0.002319999529318592 background_word_32:0.0021188253802836552 background_word_85:0.0021046148211718977 background_word_76:0.0021018981182512474 background_word_86:0.0020538958661127133 background_word_29:0.002037696689676664 pbc_word_4:0.0020298542266882743 background_word_6:0.001971540233987276 background_word_56:0.0018759929614535393 background_word_19:0.0018752311949488609 background_word_57:0.0018337892084560956 background_word_23:0.0018043244150184187 background_word_51:0.0017624495514007338 background_word_31:0.0017389757355941219 background_word_89:0.001499979626212912 background_word_75:0.00149379900289072 background_word_38:0.0011858890134317547 background_word_34:0.00116640161824405 background_word_94:0.0011047268970120576 background_word_88:0.00108243398679139 background_word_79:0.0010613892557820562 background_word_53:0.0010316275389214275 rubber_word_0:0.0008691722519150788 pbc_word_2:0.0008440612803922935 rubber_word_3:0.0008345960563028168 background_word_66:0.000574692924608765 background_word_55:0.0005119349445362176 pbc_word_3:0.0004985434800278544 background_word_1:0.0004973512038375111 background_word_84:0.0004631649314392223 background_word_99:0.0004214902801379951 background_word_49:0.0003769668585859795 background_word_71:0.00022626625492896642 background_word_93:0.00013992045352357465 background_word_54:8.227493461187447e-05 background_word_52:8.118531524466429e-05 \n",
      "################################################################################\n",
      "background_word_35:0.017002714446171043 background_word_83:0.016824668028396942 background_word_80:0.016652661397106153 background_word_48:0.016401886864848406 background_word_1:0.01497903308309517 background_word_41:0.014689825083444406 background_word_6:0.014500767870755805 background_word_77:0.01407016716969556 background_word_46:0.013668203158392046 background_word_51:0.013311429074942491 background_word_14:0.013266625455137586 background_word_62:0.013214566712656577 background_word_74:0.012993760525694934 background_word_81:0.012667336244355553 background_word_78:0.012451064097159138 background_word_5:0.012395002485167365 background_word_63:0.011915237716900128 background_word_95:0.011868937208739756 background_word_75:0.01186529177625032 background_word_99:0.011855714841964928 background_word_13:0.011729133439662781 background_word_22:0.011727342094324352 background_word_3:0.01167256552652463 background_word_29:0.011630758785668873 background_word_68:0.011572684461296362 background_word_24:0.011533100842156935 background_word_60:0.011471262143816075 background_word_36:0.011296065489651584 background_word_84:0.011266695153916319 background_word_9:0.011151971353815324 background_word_45:0.01092179306344683 background_word_90:0.01075041612625254 background_word_69:0.010747416613698777 background_word_27:0.010733557829487263 background_word_85:0.010620991333877377 background_word_96:0.010570676846383777 background_word_31:0.010467987450356172 background_word_30:0.010438296763748741 background_word_11:0.010352529931960829 background_word_57:0.010157681970544742 background_word_82:0.010057923166747603 background_word_52:0.009918360361408859 background_word_25:0.009735706487318805 background_word_97:0.00968395272929835 background_word_0:0.009561952270030562 background_word_61:0.009462880767044058 background_word_49:0.009357463374488256 background_word_18:0.009308169780732383 background_word_42:0.00915919708149674 background_word_34:0.009142929718080043 background_word_56:0.009084182620362313 background_word_16:0.00905341415371494 background_word_65:0.009025880391158909 background_word_20:0.008997599945141106 background_word_2:0.00897373605005007 background_word_10:0.008901739089411699 background_word_19:0.00888647065412271 background_word_98:0.008860825665807977 background_word_72:0.00885057429848795 background_word_86:0.008790283425164552 background_word_71:0.008767871337394992 background_word_4:0.008756956894770063 background_word_64:0.008755067628026456 background_word_8:0.008733093766311678 background_word_58:0.008717381391352497 background_word_94:0.008584500267221197 background_word_17:0.008536498636646437 background_word_88:0.008524307541834815 background_word_28:0.008465222148247856 background_word_53:0.008461020244257718 background_word_38:0.008356392441705713 background_word_47:0.00826653279042526 background_word_7:0.008161585422410899 background_word_76:0.008142910521185043 background_word_44:0.008140842958082999 background_word_70:0.008104033247234637 background_word_55:0.00804463860983371 background_word_59:0.008012622809919602 background_word_12:0.007817448593813467 background_word_54:0.00779626233993768 background_word_26:0.0077137475482643506 background_word_79:0.007446433783880864 background_word_92:0.007405238806291588 background_word_73:0.00729181764681278 background_word_87:0.007170831633490538 background_word_15:0.007084936671885525 background_word_37:0.006994441702016765 background_word_50:0.006708310169894985 background_word_66:0.006483360642343168 background_word_89:0.006302047002940199 background_word_23:0.006254294951059871 background_word_21:0.00606048762839252 background_word_32:0.006046611289658625 background_word_67:0.00597716163896024 background_word_39:0.0059649948639910536 background_word_93:0.005868274083392242 background_word_91:0.005750509835597421 background_word_40:0.0049958665397294814 background_word_33:0.004791523148293481 media_word_1:0.004364008512473372 background_word_43:0.0038519757050248724 rubber_word_2:0.003792876055277259 pbc_word_1:0.003471649782818384 rubber_word_1:0.0029087396342463473 rubber_word_4:0.002717397476863102 pbc_word_0:0.00231666051093684 media_word_4:0.0017532932663057717 pbc_word_4:0.000988369736527542 pbc_word_2:0.0008609246014912609 rubber_word_0:0.0005973369928370272 media_word_2:0.0002795474022554093 rubber_word_3:0.00019721440536738929 media_word_3:0.00015133396890199916 pbc_word_3:3.839573642962879e-05 media_word_0:3.3134543202937036e-05 \n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "plot_samples_topics(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
